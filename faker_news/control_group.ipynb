{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 控制组-受到真实新闻的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据并处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_row = pd.read_csv('df_control_clear.csv',dtype={'股票代码': str})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检视重复出现的股票代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "重复的股票代码及其出现次数：\n",
      "股票代码\n",
      "002310    9\n",
      "002717    6\n",
      "601186    5\n",
      "300197    5\n",
      "300021    4\n",
      "601238    3\n",
      "600340    3\n",
      "603636    3\n",
      "300335    3\n",
      "000018    3\n",
      "300376    3\n",
      "300262    3\n",
      "600567    3\n",
      "600068    3\n",
      "300601    3\n",
      "603658    3\n",
      "300072    3\n",
      "300145    3\n",
      "300116    3\n",
      "300362    3\n",
      "000597    2\n",
      "600530    2\n",
      "300202    2\n",
      "002205    2\n",
      "300596    2\n",
      "300198    2\n",
      "300007    2\n",
      "002153    2\n",
      "000413    2\n",
      "300223    2\n",
      "300281    2\n",
      "300356    2\n",
      "300133    2\n",
      "002431    2\n",
      "300075    2\n",
      "000869    2\n",
      "002616    2\n",
      "300370    2\n",
      "002665    2\n",
      "600835    2\n",
      "300001    2\n",
      "300397    2\n",
      "300037    2\n",
      "300210    2\n",
      "002239    2\n",
      "300094    2\n",
      "601608    2\n",
      "300363    2\n",
      "300265    2\n",
      "300225    2\n",
      "002037    2\n",
      "000558    2\n",
      "603283    2\n",
      "601179    2\n",
      "300676    2\n",
      "300334    2\n",
      "002628    2\n",
      "600737    2\n",
      "300220    2\n",
      "300708    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 统计股票代码的出现次数\n",
    "code_counts = df_control_row[\"股票代码\"].value_counts()\n",
    "\n",
    "# 找出重复的股票代码及其出现次数\n",
    "duplicate_code_counts = code_counts[code_counts > 1]\n",
    "print(\"重复的股票代码及其出现次数：\")\n",
    "print(duplicate_code_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个复杂的工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86198\\AppData\\Local\\Temp\\ipykernel_20148\\816067059.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  duplicates[\"主码\"] = duplicates[\"股票代码\"] + \"_\" + duplicates[\"新闻发布时间\"].dt.date.astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       股票代码     新闻发布时间                 主码\n",
      "5    600569 2015-01-23  600569_2015-01-23\n",
      "6    000662 2015-01-26  000662_2015-01-26\n",
      "9    600487 2015-02-01  600487_2015-02-01\n",
      "12   600060 2015-03-02  600060_2015-03-02\n",
      "15   600265 2015-03-24  600265_2015-03-24\n",
      "..      ...        ...                ...\n",
      "473  600418 2021-07-27  600418_2021-07-27\n",
      "483  601012 2022-03-01  601012_2022-03-01\n",
      "485  601012 2022-04-21  601012_2022-04-21\n",
      "487  603023 2022-06-24  603023_2022-06-24\n",
      "494  000980 2022-11-04  000980_2022-11-04\n",
      "\n",
      "[176 rows x 3 columns]\n",
      "{'300919_2022-11-04', '688567_2020-09-22', '600132_2019-01-02', '000413_2019-01-25', '600530_2016-04-25', '002411_2020-10-29', '002224_2020-06-05', '600416_2022-02-22', '600057_2015-01-09', '002359_2018-12-11', '600276_2020-09-22', '300596_2021-06-21', '600118_2019-09-06', '688661_2022-09-01', '000413_2019-04-09', '600609_2019-05-29', '002557_2020-04-08', '603555_2020-07-17', '000541_2020-04-26', '300756_2020-09-15', '002082_2019-06-25', '002226_2020-05-22', '600086_2019-02-27', '000927_2019-11-05', '601766_2019-11-19', '300567_2018-12-21', '600645_2015-10-22', '000581_2022-04-22', '002052_2020-04-17', '000790_2020-10-22', '002971_2021-02-01', '600479_2021-04-27', '603866_2020-11-27', '000716_2020-03-24', '600579_2020-08-26', '002129_2019-11-11', '002575_2020-01-14', '300749_2019-03-12', '002752_2022-09-13', '300162_2019-07-29', '603332_2022-08-04', '600668_2019-04-17', '603683_2020-06-22', '300026_2020-05-13', '600610_2017-02-13', '603429_2021-04-26', '000799_2018-12-16', '002831_2021-06-15', '603019_2019-12-19', '600071_2020-01-06', '300596_2019-11-13', '603313_2019-12-23', '603556_2019-11-19', '603816_2021-01-27', '002092_2021-04-25', '603606_2020-01-18', '600835_2022-01-12', '300876_2020-10-22', '603822_2020-12-27', '300110_2019-04-03', '836149_2022-03-14', '002179_2021-04-29', '600079_2020-01-15', '300174_2019-11-06', '000673_2015-11-27', '688299_2019-11-22', '002239_2019-08-05', '601992_2019-01-10', '601606_2020-06-01', '002841_2019-01-13', '688162_2021-11-29', '300630_2019-01-07', '002899_2021-02-23', '002388_2021-07-26', '000523_2019-05-29', '002547_2020-07-09', '300720_2020-09-01', '603358_2019-09-10', '300122_2019-05-23', '000048_2019-10-21', '688169_2020-07-01', '002564_2018-06-25', '600600_2020-12-14', '000538_2019-05-09', '300565_2022-08-22', '600779_2021-08-01', '002902_2021-03-17', '600530_2020-09-09', '839729_2022-07-18', '300716_2019-05-16', '603922_2019-11-06', '002152_2019-10-10', '600366_2020-06-16', '600835_2020-06-12', '002108_2020-10-29', '002791_2020-01-14', '603699_2019-10-30', '002481_2020-06-23', '002489_2020-11-17', '000739_2019-08-22', '002587_2019-12-01', '600211_2019-10-10', '002594_2021-02-02', '603001_2021-07-18', '603500_2019-06-27', '000597_2019-07-30', '688126_2021-04-26', '300175_2019-04-02', '000597_2021-02-23', '002239_2021-02-04', '603026_2020-11-26', '600251_2020-09-21', '002365_2021-11-04', '603626_2021-04-20', '603611_2020-08-27', '603396_2020-07-28', '600815_2019-12-19', '002335_2020-07-30', '601127_2019-12-06', '300558_2019-07-12', '603609_2020-03-29', '002824_2022-02-21', '002873_2019-11-04', '002907_2022-09-02', '600160_2019-04-18', '000630_2020-09-18', '002317_2019-08-15', '300526_2021-09-22', '600189_2020-01-08', '002137_2019-02-28', '600521_2020-03-06', '600528_2020-01-15', '300045_2019-10-28', '600234_2019-03-26', '002838_2020-01-14', '600177_2022-05-17', '002840_2019-03-04', '002157_2019-10-24', '002665_2020-08-24', '300124_2020-05-14', '002057_2021-03-29', '603600_2020-08-10', '002726_2021-01-08', '300486_2019-12-16', '300545_2020-01-13', '002665_2019-12-24', '600332_2020-08-28', '300176_2019-10-12', '300575_2020-06-10', '300586_2022-06-23', '300666_2019-05-13', '000016_2022-03-01', '000100_2021-08-10', '002702_2019-05-13'}\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'missing_primary_keys.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# 执行主程序\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 55\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m missing_primary_keys \u001b[38;5;241m=\u001b[39m find_missing_primary_keys(folder_primary_keys, duplicate_primary_keys)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Step 4: 保存结果到 Excel 文件\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mmissing_primary_keys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmissing_primary_keys.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m不存在的主码已保存到 missing_primary_keys.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dirty_test\\lib\\site-packages\\pandas\\core\\generic.py:2252\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2241\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2242\u001b[0m     df,\n\u001b[0;32m   2243\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2250\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2251\u001b[0m )\n\u001b[1;32m-> 2252\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2254\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2260\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dirty_test\\lib\\site-packages\\pandas\\io\\formats\\excel.py:934\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    930\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    937\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dirty_test\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py:199\u001b[0m, in \u001b[0;36mXlsxWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAppend mode is not supported with xlsxwriter!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatetime_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_book \u001b[38;5;241m=\u001b[39m Workbook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dirty_test\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1219\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1216\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1217\u001b[0m )\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\dirty_test\\lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'missing_primary_keys.xlsx'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: 从文件 A 中提取重复的主码\n",
    "def extract_duplicate_primary_keys(file_a_path):\n",
    "    df = pd.read_excel(file_a_path,sheet_name=0,dtype={'股票代码': str})\n",
    "    # 检查文件是否包含必要列\n",
    "    if \"股票代码\" not in df.columns or \"新闻发布时间\" not in df.columns:\n",
    "        raise ValueError(\"文件 A 必须包含 '股票代码' 和 '日期' 列\")\n",
    "\n",
    "    # 找到重复的股票代码\n",
    "    duplicate_codes = df[\"股票代码\"].value_counts()[df[\"股票代码\"].value_counts() > 1].index\n",
    "    duplicates = df[df[\"股票代码\"].isin(duplicate_codes)]\n",
    "\n",
    "    # 创建主码列\n",
    "    duplicates[\"主码\"] = duplicates[\"股票代码\"] + \"_\" + duplicates[\"新闻发布时间\"].dt.date.astype(str)\n",
    "    return duplicates[[\"股票代码\", \"新闻发布时间\", \"主码\"]]\n",
    "\n",
    "# Step 2: 从文件夹中提取主码\n",
    "def extract_primary_keys_from_folder(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    folder_primary_keys = []\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\") and \"_\" in file:\n",
    "            try:\n",
    "                # 提取文件名中的股票代码和日期\n",
    "                stock_code, date = file.split(\"_\")\n",
    "                date = date.split(\".\")[0]  # 去掉扩展名\n",
    "                folder_primary_keys.append(f\"{stock_code}_{date}\")\n",
    "            except ValueError:\n",
    "                print(f\"文件名格式不符合预期: {file}\")\n",
    "    return set(folder_primary_keys)\n",
    "\n",
    "# Step 3: 比对主码，找出不存在的\n",
    "def find_missing_primary_keys(folder_primary_keys, duplicate_primary_keys):\n",
    "    missing = duplicate_primary_keys[~duplicate_primary_keys[\"主码\"].isin(folder_primary_keys)]\n",
    "    return missing[[\"股票代码\", \"新闻发布时间\"]]  # 只保留股票代码和日期\n",
    "\n",
    "# Step 4: 主程序\n",
    "def main():\n",
    "    file_a_path = \"data_china.xlsx\"  # 替换为文件 A 的路径\n",
    "    folder_path = \"D:\\mycodelife\\workshop\\\\fake_finance\\\\ready_crawler\\dull\"  # 替换为文件夹路径\n",
    "\n",
    "    # Step 1: 提取文件 A 中的重复主码\n",
    "    duplicate_primary_keys = extract_duplicate_primary_keys(file_a_path)\n",
    "    print(duplicate_primary_keys)\n",
    "    # Step 2: 提取文件夹中的主码\n",
    "    folder_primary_keys = extract_primary_keys_from_folder(folder_path)\n",
    "    print(folder_primary_keys)\n",
    "\n",
    "    # Step 3: 找出文件夹中不存在的主码\n",
    "    missing_primary_keys = find_missing_primary_keys(folder_primary_keys, duplicate_primary_keys)\n",
    "\n",
    "    # Step 4: 保存结果到 Excel 文件\n",
    "    missing_primary_keys.to_excel(\"missing_primary_keys.xlsx\", index=False)\n",
    "    print(\"不存在的主码已保存到 missing_primary_keys.xlsx\")\n",
    "\n",
    "# 执行主程序\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照真实性删掉虚假新闻后所得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_control_row[df_control_row[\"真实性（虚假1真实0）\"] == 0]\n",
    "\n",
    "# 选择保留的列\n",
    "columns_to_drop = [\"公告地址\", \"公司简称\", \"原文链接\",\"真实性（虚假1真实0）\"]\n",
    "filtered_df = filtered_df.drop(columns=columns_to_drop)\n",
    "# 将筛选后的数据保存到新的 Excel 文件\n",
    "filtered_df.to_csv(\"df_control_clear.csv\", index=False,encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新闻文本情绪测度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "先读取原文和标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_clear = pd.read_csv(\"df_control_clear.csv\",dtype={'股票代码':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_content = df_control_clear[[\"股票代码\",\"原文\",\"新闻发布时间\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title = df_control_clear[[\"股票代码\",\"标题\",\"新闻发布时间\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "切割文本长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(row, max_length=500):\n",
    "    \"\"\"\n",
    "    将原文按 max_length 分割，并为每段保留对应的主码（包括股票代码和新闻发布时间）。\n",
    "    \"\"\"\n",
    "    text = row[\"原文\"]\n",
    "    code = row[\"股票代码\"]\n",
    "    date = row[\"新闻发布时间\"]\n",
    "    \n",
    "    # 按长度 max_length 分割\n",
    "    chunks = [text[i:i + max_length] for i in range(0, len(text), max_length)]\n",
    "    \n",
    "    # 返回主码（股票代码、新闻发布时间）和分割后的内容\n",
    "    return [{\"股票代码\": code, \"新闻发布时间\": date, \"分段内容\": chunk} for chunk in chunks]\n",
    "\n",
    "# 应用函数，将结果展开为一个新 DataFrame\n",
    "result = df_content.apply(split_text, axis=1)  # 每行应用\n",
    "df_content_cut = pd.DataFrame([item for sublist in result for item in sublist])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用BERT\n",
    "同虚假新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\dirty_test\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bardsai/finance-sentiment-zh-fast\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bardsai/finance-sentiment-zh-fast\")\n",
    "nlp_bardsai = pipeline(\"text-classification\", model=\"bardsai/finance-sentiment-zh-fast\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对虚假新闻标题进行情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件已生成：情绪分析结果.csv\n"
     ]
    }
   ],
   "source": [
    "# 对每一段进行情绪分析\n",
    "df_title[\"情绪分析结果\"] = df_title[\"标题\"].apply(nlp_bardsai)\n",
    "\n",
    "# 分解情绪分析结果并扩展列\n",
    "df_title[\"情绪标签\"] = df_title[\"情绪分析结果\"].apply(lambda x: x[0][\"label\"])\n",
    "df_title[\"情绪分数\"] = df_title[\"情绪分析结果\"].apply(lambda x: x[0][\"score\"])\n",
    "df_title = df_title.drop(columns=[\"情绪分析结果\"])\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df_title.to_csv(\"badrdsai_result_title_control_group.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"CSV 文件已生成：情绪分析结果.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对新闻文本进行情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 文件已生成：情绪分析结果.csv\n"
     ]
    }
   ],
   "source": [
    "# 对每一段进行情绪分析\n",
    "df_content_cut[\"情绪分析结果\"] = df_content_cut[\"分段内容\"].apply(nlp_bardsai)\n",
    "\n",
    "# 分解情绪分析结果并扩展列\n",
    "df_content_cut[\"情绪标签\"] = df_content_cut[\"情绪分析结果\"].apply(lambda x: x[0][\"label\"])\n",
    "df_content_cut[\"情绪分数\"] = df_content_cut[\"情绪分析结果\"].apply(lambda x: x[0][\"score\"])\n",
    "df_content_cut = df_content_cut.drop(columns=[\"情绪分析结果\"])\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df_content_cut.to_csv(\"badrdsai_result_content_control_group.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"CSV 文件已生成：情绪分析结果.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理情绪分析结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>股票代码</th>\n",
       "      <th>新闻发布时间</th>\n",
       "      <th>分段内容</th>\n",
       "      <th>情绪标签</th>\n",
       "      <th>情绪分数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000156</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>华数传媒(000156)周日晚间公告称，其全资子公司浙江华数传媒资本管理有限公司与金石投资有...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002037</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>久联发展1月4日晚间公告称，公司于2014年12月30日收到公司下属全资子公司新联爆破集团关...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002055</td>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>得润电子7日公告，公司拟在广东省鹤山市建设运营得润工业园项目，以进一步扩大公司产能和规模，完...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300220</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>金运激光1月8日晚间公告称，公司控股子公司武汉落地创意文化传播有限公司（简称“落地创意”）1...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600057</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>象屿股份（600057）9日晚间公告，近日，公司控股股东象屿集团与黑龙江省粮食局签署关于粮食...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>002752</td>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>\\n涉嫌证券市场操纵 昇兴股份董事长被罚100万\\n2022-09-13 02:25 ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>002752</td>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>金属容器委员会第七届委员会副主任委员、福州市外商投资企业协会第六届理事会副会长。现任昇兴股份...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>002752</td>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>赔长期处于探索阶段。据不完全统计，目前，国内仅有两例投资者以被告操纵证券市场为由索赔胜诉。\\...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>002752</td>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>东、实际控制人李广胜家属的通知，李广胜因涉嫌操纵证券、期货市场罪被湖州市公安局采取刑事拘留措...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.999913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>300919</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>2022年11月3日晚间，A股公司中伟股份(300919.SZ)公告，与欣旺达电子股份有限公...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.999489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       股票代码      新闻发布时间                                               分段内容  \\\n",
       "0    000156  2015-01-04  华数传媒(000156)周日晚间公告称，其全资子公司浙江华数传媒资本管理有限公司与金石投资有...   \n",
       "1    002037  2015-01-04  久联发展1月4日晚间公告称，公司于2014年12月30日收到公司下属全资子公司新联爆破集团关...   \n",
       "2    002055  2015-01-07  得润电子7日公告，公司拟在广东省鹤山市建设运营得润工业园项目，以进一步扩大公司产能和规模，完...   \n",
       "3    300220  2015-01-08  金运激光1月8日晚间公告称，公司控股子公司武汉落地创意文化传播有限公司（简称“落地创意”）1...   \n",
       "4    600057  2015-01-09  象屿股份（600057）9日晚间公告，近日，公司控股股东象屿集团与黑龙江省粮食局签署关于粮食...   \n",
       "..      ...         ...                                                ...   \n",
       "718  002752  2022-09-13     \\n涉嫌证券市场操纵 昇兴股份董事长被罚100万\\n2022-09-13 02:25 ...   \n",
       "719  002752  2022-09-13  金属容器委员会第七届委员会副主任委员、福州市外商投资企业协会第六届理事会副会长。现任昇兴股份...   \n",
       "720  002752  2022-09-13  赔长期处于探索阶段。据不完全统计，目前，国内仅有两例投资者以被告操纵证券市场为由索赔胜诉。\\...   \n",
       "721  002752  2022-09-13  东、实际控制人李广胜家属的通知，李广胜因涉嫌操纵证券、期货市场罪被湖州市公安局采取刑事拘留措...   \n",
       "722  300919  2022-11-04  2022年11月3日晚间，A股公司中伟股份(300919.SZ)公告，与欣旺达电子股份有限公...   \n",
       "\n",
       "         情绪标签      情绪分数  \n",
       "0     neutral  0.999913  \n",
       "1     neutral  0.999914  \n",
       "2    positive  0.999719  \n",
       "3     neutral  0.999891  \n",
       "4     neutral  0.999913  \n",
       "..        ...       ...  \n",
       "718   neutral  0.999909  \n",
       "719   neutral  0.999903  \n",
       "720   neutral  0.999904  \n",
       "721   neutral  0.999913  \n",
       "722  positive  0.999489  \n",
       "\n",
       "[723 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content_analysis = pd.read_csv(\"badrdsai_result_content_control_group.csv\",dtype={\"股票代码\":str})\n",
    "df_content_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增列：判断是否为 positive、neutral 和 negative\n",
    "df_content_analysis[\"neutral\"] = df_content_analysis[\"情绪标签\"].apply(lambda x: 1 if x == \"neutral\" else 0)\n",
    "df_content_analysis[\"positive\"] = df_content_analysis[\"情绪标签\"].apply(lambda x: 1 if x == \"positive\" else 0)\n",
    "df_content_analysis[\"negative\"] = df_content_analysis[\"情绪标签\"].apply(lambda x: 1 if x == \"negative\" else 0)\n",
    "\n",
    "# 分组统计\n",
    "result = df_content_analysis.groupby([\"股票代码\",\"新闻发布时间\"]).agg(\n",
    "    # 中性均值，若无中性情绪，填充为 0\n",
    "    中性均值=(\"情绪分数\", lambda x: x[df_content_analysis.loc[x.index, \"neutral\"] == 1].mean() if any(df_content_analysis.loc[x.index, \"neutral\"] == 1) else 0),\n",
    "    # 积极均值，若无积极情绪，填充为 0\n",
    "    积极均值=(\"情绪分数\", lambda x: x[df_content_analysis.loc[x.index, \"positive\"] == 1].mean() if any(df_content_analysis.loc[x.index, \"positive\"] == 1) else 0),\n",
    "    # 消极均值，若无消极情绪，填充为 0\n",
    "    消极均值=(\"情绪分数\", lambda x: x[df_content_analysis.loc[x.index, \"negative\"] == 1].mean() if any(df_content_analysis.loc[x.index, \"negative\"] == 1) else 0),\n",
    "    # 中性占比\n",
    "    中性占比=(\"neutral\", \"mean\"),\n",
    "    # 积极占比\n",
    "    积极占比=(\"positive\", \"mean\"),\n",
    "    # 消极占比\n",
    "    消极占比=(\"negative\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "# 计算每类加权分数\n",
    "result[\"中性分数\"] = result[\"中性均值\"] * result[\"中性占比\"]\n",
    "result[\"积极分数\"] = result[\"积极均值\"] * result[\"积极占比\"]\n",
    "result[\"消极分数\"] = result[\"消极均值\"] * result[\"消极占比\"]\n",
    "\n",
    "# 仅保留所需列\n",
    "result = result[[\"股票代码\",\"新闻发布时间\",\"中性分数\", \"积极分数\", \"消极分数\"]]\n",
    "\n",
    "# 保存结果到 CSV 文件\n",
    "result.to_csv(\"bardsai_analysis_content_control.csv\", index=False, encoding=\"utf-8-sig\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirty_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
