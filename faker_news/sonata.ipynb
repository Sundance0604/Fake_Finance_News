{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af9221c",
   "metadata": {},
   "source": [
    "# 最后的流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6135f9f",
   "metadata": {},
   "source": [
    "# 重新处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e9056",
   "metadata": {},
   "source": [
    "## 多CAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c525bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. 读取数据\n",
    "df = pd.read_excel('data_guba.xlsx')\n",
    "\n",
    "# 2. 提取异常收益列\n",
    "ar_cols = [col for col in df.columns if col.startswith('AR_')]\n",
    "id_vars = [col for col in df.columns if col not in ar_cols]\n",
    "\n",
    "# 3. 宽转长\n",
    "df_long = pd.melt(df, id_vars=id_vars, value_vars=ar_cols,\n",
    "                  var_name='time', value_name='AR')\n",
    "df_long['time_num'] = df_long['time'].str.replace('AR_', '').astype(int)\n",
    "\n",
    "# 4. 缺失值处理\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_long[['AR']] = imputer.fit_transform(df_long[['AR']])\n",
    "\n",
    "# 6. 重命名\n",
    "rename_dict = {\n",
    "    '年报资产报酬率（%）': 'AssetReturn',\n",
    "    '年报资产报酬率TTM（%）': 'AssetReturn_TTM',\n",
    "    '年报营业利润率（%）': 'OperatingProfitMargin',\n",
    "    '流动比率（%）': 'CurrentRatio',\n",
    "    '速动比率（%）': 'QuickRatio',\n",
    "    '净资产负债率（%）': 'NetDebtRatio',\n",
    "    '年报总资产周转率（次）': 'AssetTurnover',\n",
    "    '年报总资产周转率TTM（次）': 'AssetTurnover_TTM',\n",
    "    '资产负债率（%）': 'DebtRatio',\n",
    "    '年报非流动资产/总资产（%）': 'NonCurrentAsset_Ratio'\n",
    "}\n",
    "df_long.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# 7. 控制变量列表\n",
    "control_vars = [\n",
    "    'AssetReturn', 'AssetReturn_TTM', 'OperatingProfitMargin',\n",
    "    'CurrentRatio', 'QuickRatio', 'NetDebtRatio',\n",
    "    'AssetTurnover', 'AssetTurnover_TTM', 'DebtRatio',\n",
    "    'NonCurrentAsset_Ratio'\n",
    "]\n",
    "\n",
    "# 8. 统一id_vars\n",
    "id_vars = control_vars + ['is_authoritative']\n",
    "\n",
    "# 9. 定义计算CAR的函数\n",
    "def calculate_car(df_long, start, end, id_vars=id_vars):\n",
    "    df_car = df_long[df_long['time_num'].between(start, end)]\n",
    "    df_car = df_car.groupby(id_vars)['AR'].sum().reset_index()\n",
    "    df_car.rename(columns={'AR': f'CAR_{start}_{end}'}, inplace=True)\n",
    "    return df_car\n",
    "\n",
    "# 10. 计算多个时间窗的CAR\n",
    "car_windows = [(-1, 3), (-1, 1), (-1, 2), (-1,4), (-1,5)]\n",
    "car_dfs = [calculate_car(df_long, start, end) for (start, end) in car_windows]\n",
    "\n",
    "# 11. 合并所有CAR结果\n",
    "from functools import reduce\n",
    "df_car_merged = reduce(lambda left, right: pd.merge(left, right, on=id_vars, how='outer'), car_dfs)\n",
    "\n",
    "# 12. 合并回原始数据（删除重复列）\n",
    "df_final = df_long.drop(columns=['time', 'time_num']).drop_duplicates(subset=id_vars)\n",
    "df_final = df_final.merge(df_car_merged, on=id_vars, how='left')\n",
    "\n",
    "# 13. 保存到Excel：每个CAR时间窗一列\n",
    "df_final.to_excel('CAR_results_combined.xlsx', index=False)\n",
    "\n",
    "# ✅ 额外（如需按sheet保存）：\n",
    "with pd.ExcelWriter('CAR_results_by_window.xlsx', engine='openpyxl') as writer:\n",
    "    for (start, end), df_car in zip(car_windows, car_dfs):\n",
    "        df_car.to_excel(writer, sheet_name=f'CAR_{start}_{end}', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9c4c02",
   "metadata": {},
   "source": [
    "## 新控制变量 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea652b",
   "metadata": {},
   "source": [
    "### 提取年份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efd8adf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     股票代码 event date     交易日0_x  市场类型_x     alpha      beta  AssetReturn  \\\n",
      "0  600141 2015-01-02 2015-01-06       1  0.000835  0.124236       3.9631   \n",
      "1     156 2015-01-04 2015-01-05       4  0.000088  0.899838       5.6577   \n",
      "2    2037 2015-01-04 2015-01-05       4  0.002651  0.579189       4.0469   \n",
      "3    2055 2015-01-07 2015-01-07       4 -0.000427  0.754313       3.1448   \n",
      "4    2030 2015-01-07 2015-01-07       4  0.000185  1.327853       6.7978   \n",
      "\n",
      "   AssetReturn_TTM  OperatingProfitMargin  CurrentRatio  ...          mean  \\\n",
      "0           0.4989                 1.2332        0.4475  ...  1.333333e-01   \n",
      "1           5.8418                17.8081        3.4528  ... -2.222222e-02   \n",
      "2           1.1130                 3.4687        0.8489  ...  1.666667e-01   \n",
      "3           1.3823                 1.9199        1.1927  ... -5.551115e-18   \n",
      "4           5.0844                 5.9033        2.1392  ...  9.800000e-02   \n",
      "\n",
      "   variance  is_authoritative        AR  CAR_-1_3  CAR_-1_1  CAR_-1_2  \\\n",
      "0  0.172500                 0 -0.022851 -0.003397  0.039991  0.032999   \n",
      "1  0.133778                 0  0.006806 -0.097709 -0.135430 -0.088696   \n",
      "2  0.050000                 1 -0.009874 -0.005300  0.013700  0.012334   \n",
      "3  0.148889                 1 -0.036850  0.024887  0.023851  0.028528   \n",
      "4  0.189588                 0 -0.053988  0.012528  0.008230  0.000718   \n",
      "\n",
      "   CAR_-1_4  CAR_-1_5  year  \n",
      "0 -0.047589 -0.030525  2015  \n",
      "1 -0.098276 -0.106243  2015  \n",
      "2 -0.010016 -0.036734  2015  \n",
      "3  0.044884  0.032688  2015  \n",
      "4  0.091836  0.128702  2015  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 Excel 文件\n",
    "df = pd.read_excel(\"CAR_results_combined.xlsx\")\n",
    "\n",
    "# 确保 event date 列是 datetime 类型\n",
    "df[\"event date\"] = pd.to_datetime(df[\"event date\"])\n",
    "\n",
    "# 提取年份并创建新列 year\n",
    "df[\"year\"] = df[\"event date\"].dt.year\n",
    "\n",
    "# 查看结果\n",
    "print(df.head())\n",
    "\n",
    "# 如果需要保存回 Excel\n",
    "df.to_excel(\"CAR_results_combined.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd279d1",
   "metadata": {},
   "source": [
    "### 归并AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c073d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两个 Excel 文件已成功根据 (股票代码, event date) 合并，并保存到 merged_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('CAR_results_combined.xlsx')\n",
    "df2 = pd.read_excel(\"data_guba.xlsx\")\n",
    "\n",
    "# 2. 如果需要，统一 event date 的数据类型（例如转换为日期类型）\n",
    "df1['股票代码'] = df1['股票代码'].astype(str)\n",
    "df2['股票代码'] = df2['股票代码'].astype(str)\n",
    "\n",
    "df1['event date'] = pd.to_datetime(df1['event date'])\n",
    "df2['event date'] = df2['event date'].astype(str).str.strip()\n",
    "df2['event date'] = df2['event date'].str.split().str[0]\n",
    "df2['event date'] = pd.to_datetime(df2['event date'])\n",
    "\n",
    "# 3. 根据共同键（股票代码, event date）进行合并\n",
    "# 这里采用 inner join：只保留两个表中都存在的匹配行\n",
    "merged_df = pd.merge(df1, df2, on=['股票代码', 'event date'], how='left')\n",
    "\n",
    "# 4. 将合并后的结果保存到新的 Excel 文件中\n",
    "merged_df.to_excel('CAR_results_combined.xlsx', index=False)\n",
    "\n",
    "print(\"两个 Excel 文件已成功根据 (股票代码, event date) 合并，并保存到 merged_output.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66848fff",
   "metadata": {},
   "source": [
    "### 合并新控制变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451d4d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两个 Excel 文件已成功根据 (股票代码, event date) 合并，并保存到 merged_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('CAR_results_combined.xlsx')\n",
    "df2 = pd.read_excel(\"control_vars.xlsx\")\n",
    "\n",
    "# 2. 如果需要，统一 event date 的数据类型（例如转换为日期类型）\n",
    "df1['股票代码'] = df1['股票代码'].astype(str)\n",
    "df2['股票代码'] = df2['股票代码'].astype(str)\n",
    "\n",
    "\n",
    "# 3. 根据共同键（股票代码, event date）进行合并\n",
    "# 这里采用 inner join：只保留两个表中都存在的匹配行\n",
    "merged_df = pd.merge(df1, df2, on=['股票代码', 'year'], how='left')\n",
    "\n",
    "# 4. 将合并后的结果保存到新的 Excel 文件中\n",
    "merged_df.to_excel('last_step.xlsx', index=False)\n",
    "\n",
    "print(\"两个 Excel 文件已成功根据 (股票代码, event date) 合并，并保存到 merged_output.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa661ca",
   "metadata": {},
   "source": [
    "### 合并姜富伟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8f1eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "两个 Excel 文件已成功根据 (股票代码, event date) 合并，并保存到 merged_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_excel('last_step.xlsx')\n",
    "df2 = pd.read_excel(\"fuwei.xlsx\")\n",
    "\n",
    "# 2. 如果需要，统一 event date 的数据类型（例如转换为日期类型）\n",
    "df1['股票代码'] = df1['股票代码'].astype(str)\n",
    "df2['股票代码'] = df2['股票代码'].astype(str)\n",
    "df1['event date'] = pd.to_datetime(df1['event date'])\n",
    "df2['event date'] = pd.to_datetime(df2['event date'])\n",
    "\n",
    "# 3. 根据共同键（股票代码, event date）进行合并\n",
    "# 这里采用 inner join：只保留两个表中都存在的匹配行\n",
    "merged_df = pd.merge(df1, df2, on=['股票代码', 'event date'], how='left')\n",
    "\n",
    "# 4. 将合并后的结果保存到新的 Excel 文件中\n",
    "merged_df.to_excel('last_step.xlsx', index=False)\n",
    "\n",
    "print(\"两个 Excel 文件已成功根据 (股票代码, event date) 合并，并保存到 merged_output.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5340c",
   "metadata": {},
   "source": [
    "## 计算新控制变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5b5c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 Excel 文件\n",
    "df = pd.read_excel(\"last_step.xlsx\")\n",
    "\n",
    "# \n",
    "df['Ind'] = df['行业代码'].astype('category').cat.codes\n",
    "\n",
    "df['Firm'] = df['股票代码'].astype('category').cat.codes\n",
    "\n",
    "# 如果需要保存回 Excel\n",
    "df.to_excel(\"last_step.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a0ee0d",
   "metadata": {},
   "source": [
    "# 描述性统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7036364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "描述性统计已保存到 descriptive_statistics.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. 读取 Excel 文件（请替换路径）\n",
    "df = pd.read_excel('last_step.xlsx')\n",
    "\n",
    "# 2. 指定你要统计的列（可手动列出，或用正则/前缀匹配）\n",
    "columns_to_describe = ['ARE','OPM','CR','QR','ND','AT','sentiment','CAR_-1_3','TR','Ind','Soe','Dual','Indep','Lev','Size','Big4']  \n",
    "\n",
    "# 3. 计算描述性统计\n",
    "desc_stats = df[columns_to_describe].agg(['mean', 'median', 'std', 'min', 'max']).T\n",
    "desc_stats.columns = ['均值', '中位数', '标准差', '最小值', '最大值']\n",
    "\n",
    "# 4. 将结果保存为文本文件\n",
    "with open('descriptive_statistics.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(desc_stats.to_string())\n",
    "\n",
    "print(\"描述性统计已保存到 descriptive_statistics.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee6dc9",
   "metadata": {},
   "source": [
    "# 基准回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc37d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归结果已保存到 regression_results.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# 读取数据（假设数据存储在 data.csv）\n",
    "df = pd.read_excel(\"last_step.xlsx\")\n",
    "add_control_vars = True  # 是否添加控制变量\n",
    "# 定义变量\n",
    "dependent_var = \"CAR_-1_3\"  # 被解释变量\n",
    "independent_var = \"sentiment\"  # 解释变量\n",
    "control_vars = ['ARE', 'OPM', 'CR', 'QR', 'ND', 'AT', 'Soe', 'Dual', 'Indep', 'Lev', 'Size', 'Big4']  # 控制变量\n",
    "\n",
    "# 添加固定效应（行业 Ind，假设是分类变量）\n",
    "df = pd.get_dummies(df, columns=['year'], drop_first=True)  # One-hot 编码行业固定效应\n",
    "\n",
    "# 构建回归模型\n",
    "if add_control_vars:\n",
    "    # 如果有控制变量，添加到模型中\n",
    "    X = df[[independent_var] + control_vars ]  # 解释变量+控制变量+行业固定效应\n",
    "    \n",
    "else:\n",
    "    X = df[[independent_var]]  # 解释变量\n",
    "\n",
    "X = sm.add_constant(X)  # 添加常数项\n",
    "y = df[dependent_var]  # 被解释变量\n",
    "\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y.loc[X.index]  # 确保 y 也同步删除相应行\n",
    "\n",
    "\n",
    "# 运行 OLS 回归\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# 设置小数位数\n",
    "decimal_places = 5  # 你可以自由修改这个值\n",
    "\n",
    "# 获取回归结果，并设置小数位数\n",
    "coefficients = model.params.round(decimal_places)  # 回归系数\n",
    "p_values = model.pvalues.round(decimal_places)  # p 值\n",
    "std_errors = model.bse.round(decimal_places)  # 标准误差\n",
    "r_squared = round(model.rsquared, decimal_places)  # R²\n",
    "adj_r_squared = round(model.rsquared_adj, decimal_places)  # 调整 R²\n",
    "\n",
    "# 组织输出内容\n",
    "output_text = []\n",
    "output_text.append(\"回归结果（OLS 估计）\\n\")\n",
    "output_text.append(f\"R²: {r_squared},  调整 R²: {adj_r_squared}\\n\")\n",
    "output_text.append(\"\\n回归系数（Coefficient）：\\n\")\n",
    "output_text.append(coefficients.to_string())\n",
    "output_text.append(\"\\n\\n标准误差（Standard Error）：\\n\")\n",
    "output_text.append(std_errors.to_string())\n",
    "output_text.append(\"\\n\\nP 值（P-Values）：\\n\")\n",
    "output_text.append(p_values.to_string())\n",
    "\n",
    "# 写入 txt 文件\n",
    "with open(\"regression_results.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(output_text))\n",
    "\n",
    "print(\"回归结果已保存到 regression_results.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67625f2d",
   "metadata": {},
   "source": [
    "# 修订：新闻发布日期与临近交易日"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefba2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归公式： CAR ~ mismatch + ARE + OPM + CR + QR + ND + AT + Soe + Dual + Indep + Lev + Size + Big4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# 1. 读取数据（请将 'your_data.csv' 替换为你的数据文件路径）\n",
    "df = pd.read_excel('last_step.xlsx')\n",
    "\n",
    "# 2. 构造“不一致”变量：当“交易日0”与“event date”不一致时，mismatch=1，否则为0\n",
    "df['mismatch'] = (df['交易日0'] != df['event date']).astype(int)\n",
    "\n",
    "# 3. 计算事件窗 (-1, 1) 的累计异常收益 CAR = AR_-1 + AR_0 + AR_1\n",
    "df['CAR'] = df['AR_-1'] + df['AR_0'] + df['AR_1']\n",
    "control_vars = ['ARE', 'OPM', 'CR', 'QR', 'ND', 'AT', 'Soe', 'Dual', 'Indep', 'Lev', 'Size', 'Big4']\n",
    "\n",
    "\n",
    "# 6. 构造回归公式\n",
    "formula = 'CAR ~ mismatch'\n",
    "if control_vars:\n",
    "    formula += ' + ' + ' + '.join(control_vars)\n",
    "\n",
    "print(\"回归公式：\", formula)\n",
    "\n",
    "# 7. 使用 OLS 建模\n",
    "model = smf.ols(formula, data=df).fit()\n",
    "summary_text = model.summary().as_text()\n",
    "with open('moderation_OLS_summary.txt', 'w') as f:\n",
    "    f.write(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72065a5",
   "metadata": {},
   "source": [
    "# 修订：DID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25aef946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归公式： AR ~ truth + Post + did + ARE + OPM + CR + QR + ND + AT + Soe + Dual + Indep + Lev + Size + Big4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. 读取数据（请将 'your_data.csv' 替换为你的数据文件路径）\n",
    "df = pd.read_excel('last_step.xlsx')\n",
    "\n",
    "# 2. 提取所有以 \"AR_\" 开头的列作为事件窗口的异常收益\n",
    "ar_cols = [col for col in df.columns if col.startswith('AR_')]\n",
    "\n",
    "# 3. 确定 id_vars：保留除异常收益以外的列（假设已删去股票代码、event date、交易日0、市场类型等变量）\n",
    "id_vars = [col for col in df.columns if col not in ar_cols]\n",
    "\n",
    "# 4. 将数据从宽格式转换为长格式，生成新列 \"time\"（事件时点）和 \"AR\"（异常收益）\n",
    "df_long = pd.melt(df, id_vars=id_vars, value_vars=ar_cols, var_name='time', value_name='AR')\n",
    "\n",
    "# 5. 将 “time” 列转换为数值型变量\n",
    "#    假设 time 格式为 \"AR_-10\", \"AR_0\", \"AR_10\" 等\n",
    "df_long['time_num'] = df_long['time'].str.replace('AR_', '').astype(int)\n",
    "\n",
    "# 6. 对 AR 列进行均值插补，处理缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_long[['AR']] = imputer.fit_transform(df_long[['AR']])\n",
    "\n",
    "# 7. 构造处理后时点的虚拟变量：当 time_num >= 0 时取 1，否则取 0\n",
    "df_long['Post'] = (df_long['time_num'] >= 0).astype(int)\n",
    "\n",
    "# 8. 构造 DID 交互项：did = truth * Post\n",
    "#    这里假设 truth 已经为 0/1 变量（1 表示受处理组，0 表示对照组）\n",
    "df_long['did'] = df_long['truth'] * df_long['Post']\n",
    "control_vars = ['ARE', 'OPM', 'CR', 'QR', 'ND', 'AT', 'Soe', 'Dual', 'Indep', 'Lev', 'Size', 'Big4']\n",
    "formula = 'AR ~ truth + Post + did'\n",
    "if control_vars:\n",
    "    formula += ' + ' + ' + '.join(control_vars)\n",
    "\n",
    "print(\"回归公式：\", formula)\n",
    "\n",
    "# 12. 使用 OLS 估计 DID 模型（不采用分组聚类稳健标准误）\n",
    "model = smf.ols(formula, data=df_long).fit()\n",
    "\n",
    "# 使用 StringIO 捕获回归摘要输出\n",
    "summary_text = model.summary().as_text()\n",
    "\n",
    "# 将回归摘要写入文件\n",
    "with open('model_summary.txt', 'w') as f:\n",
    "    f.write(summary_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2969d",
   "metadata": {},
   "source": [
    "# 解释变量的稳健性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51839da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归公式： Q(\"CAR_-1_3\") ~ Q(\"final_score\") + ARE + OPM + CR + QR + ND + AT + Soe + Dual + Indep + Lev + Size + Big4 + truth\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# 1. 读取数据（请将 'your_data.csv' 替换为你的数据文件路径）\n",
    "df = pd.read_excel('last_step.xlsx')\n",
    "\n",
    "\n",
    "control_vars = ['ARE', 'OPM', 'CR', 'QR', 'ND', 'AT', 'Soe', 'Dual', 'Indep', 'Lev', 'Size', 'Big4','truth']\n",
    "\n",
    "\n",
    "# 6. 构造回归公式\n",
    "formula = 'Q(\"CAR_-1_3\") ~ Q(\"final_score\")'\n",
    "if control_vars:\n",
    "    formula += ' + ' + ' + '.join(control_vars)\n",
    "\n",
    "print(\"回归公式：\", formula)\n",
    "\n",
    "# 7. 使用 OLS 建模\n",
    "model = smf.ols(formula, data=df).fit()\n",
    "summary_text = model.summary().as_text()\n",
    "with open('moderation_OLS_summary.txt', 'w') as f:\n",
    "    f.write(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3fb8b",
   "metadata": {},
   "source": [
    "# 被解释变量的稳健性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84e24c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归公式： Q(\"CAR_-1_5\") ~ sentiment + ARE + OPM + CR + QR + ND + AT + Soe + Dual + Indep + Lev + Size + Big4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# 1. 读取数据（请将 'your_data.csv' 替换为你的数据文件路径）\n",
    "df = pd.read_excel('last_step.xlsx')\n",
    "\n",
    "\n",
    "control_vars = ['ARE', 'OPM', 'CR', 'QR', 'ND', 'AT', 'Soe', 'Dual', 'Indep', 'Lev', 'Size', 'Big4']\n",
    "\n",
    "\n",
    "# 6. 构造回归公式\n",
    "formula = 'Q(\"CAR_-1_5\") ~ sentiment'\n",
    "if control_vars:\n",
    "    formula += ' + ' + ' + '.join(control_vars)\n",
    "\n",
    "print(\"回归公式：\", formula)\n",
    "\n",
    "# 7. 使用 OLS 建模\n",
    "model = smf.ols(formula, data=df).fit()\n",
    "summary_text = model.summary().as_text()\n",
    "with open('moderation_OLS_summary.txt', 'w') as f:\n",
    "    f.write(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d0ae1",
   "metadata": {},
   "source": [
    "# 修正：调节效应"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47be16a",
   "metadata": {},
   "source": [
    "## 直接回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c7b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归公式： Q(\"CAR_-1_3\") ~ truth+ is_authoritative + truth : is_authoritative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# 1. 读取数据（请将 'your_data.csv' 替换为你的数据文件路径）\n",
    "df = pd.read_excel('last_step.xlsx')\n",
    "\n",
    "\n",
    "control_vars = ['ARE', 'OPM', 'CR', 'QR', 'ND', 'AT', 'Soe', 'Dual', 'Indep', 'Lev', 'Size', 'Big4']\n",
    "\n",
    "\n",
    "# 6. 构造回归公式\n",
    "formula = 'Q(\"CAR_-1_3\") ~ truth+ is_authoritative + truth : is_authoritative'\n",
    "if control_vars:\n",
    "    formula += ' + ' + ' + '.join(control_vars)\n",
    "\n",
    "print(\"回归公式：\", formula)\n",
    "\n",
    "# 7. 使用 OLS 建模\n",
    "model = smf.ols(formula, data=df).fit()\n",
    "summary_text = model.summary().as_text()\n",
    "with open('moderation_OLS_summary.txt', 'w') as f:\n",
    "    f.write(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d87b72",
   "metadata": {},
   "source": [
    "## 分组DID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab0c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 1. 读取数据（请将 'your_data.csv' 替换为你的数据文件路径）\n",
    "df = pd.read_excel('last_step.xlsx')\n",
    "\n",
    "# 2. 提取所有以 \"AR_\" 开头的列作为事件窗口的异常收益\n",
    "ar_cols = [col for col in df.columns if col.startswith('AR_')]\n",
    "\n",
    "# 3. 确定 id_vars：保留除异常收益以外的列（假设已删去股票代码、event date、交易日0、市场类型等变量）\n",
    "id_vars = [col for col in df.columns if col not in ar_cols]\n",
    "\n",
    "# 4. 将数据从宽格式转换为长格式，生成新列 \"time\"（事件时点）和 \"AR\"（异常收益）\n",
    "df_long = pd.melt(df, id_vars=id_vars, value_vars=ar_cols, var_name='time', value_name='AR')\n",
    "\n",
    "# 5. 将 “time” 列转换为数值型变量\n",
    "#    假设 time 格式为 \"AR_-10\", \"AR_0\", \"AR_10\" 等\n",
    "df_long['time_num'] = df_long['time'].str.replace('AR_', '').astype(int)\n",
    "\n",
    "# 6. 对 AR 列进行均值插补，处理缺失值\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_long[['AR']] = imputer.fit_transform(df_long[['AR']])\n",
    "\n",
    "# 7. 构造处理后时点的虚拟变量：当 time_num >= 0 时取 1，否则取 0\n",
    "df_long['Post'] = (df_long['time_num'] >= 0).astype(int)\n",
    "\n",
    "# 8. 构造 DID 交互项：did = truth * Post\n",
    "#    这里假设 truth 已经为 0/1 变量（1 表示受处理组，0 表示对照组）\n",
    "df_long['did'] = df_long['truth'] * df_long['Post']\n",
    "control_vars = ['ARE', 'OPM', 'CR', 'QR', 'ND', 'AT', 'Soe', 'Dual', 'Indep', 'Lev', 'Size', 'Big4']\n",
    "\n",
    "\n",
    "# 6. 构造回归公式\n",
    "formula = 'AR ~ truth+ Post + did'\n",
    "if control_vars:\n",
    "    formula += ' + ' + ' + '.join(control_vars)\n",
    "df_auth = df_long[df_long['is_authoritative'] == 1]\n",
    "df_non_auth = df_long[df_long['is_authoritative'] == 0]\n",
    "\n",
    "# 针对权威来源组运行回归\n",
    "model_auth = smf.ols(formula, data=df_auth).fit()\n",
    "summary_auth = model_auth.summary().as_text()\n",
    "\n",
    "# 针对非权威来源组运行回归\n",
    "model_non_auth = smf.ols(formula, data=df_non_auth).fit()\n",
    "summary_non_auth = model_non_auth.summary().as_text()\n",
    "\n",
    "# 将两个回归摘要保存到不同的文件中（也可以保存到同一个文件）\n",
    "with open('model_summary_authoritative.txt', 'w') as f:\n",
    "    f.write(\"DID Regression Results for is_authoritative = 1 (Authoritative Sources):\\n\")\n",
    "    f.write(summary_auth)\n",
    "\n",
    "with open('model_summary_non_authoritative.txt', 'w') as f:\n",
    "    f.write(\"DID Regression Results for is_authoritative = 0 (Non-authoritative Sources):\\n\")\n",
    "    f.write(summary_non_auth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dirty_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
