{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The model class you are passing has a `config_class` attribute that is not consistent with the config class you passed (model has <class 'transformers_modules.baichuan-inc.Baichuan-13B-Chat.e3e1498bb6b7fb0bcb5a65679c09b862d7c29301.configuration_baichuan.BaichuanConfig'> and you passed <class 'transformers_modules.Go4miii.DISC-FinLLM.8e235cb9e81f952702b0b90c5f3292a1089b0dba.configuration_baichuan.BaichuanConfig'>. Fix one of those so they match!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpeft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftModel, PeftConfig\n\u001b[0;32m      6\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGo4miii/DISC-FinLLM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mgeneration_config \u001b[38;5;241m=\u001b[39m GenerationConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m     11\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     12\u001b[0m     model_path, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\FinLLM\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:558\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m         model_class\u001b[38;5;241m.\u001b[39mregister_for_auto_class(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 558\u001b[0m         \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    560\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    561\u001b[0m     )\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\FinLLM\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:584\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.register\u001b[1;34m(cls, config_class, model_class, exist_ok)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03mRegister a new model for this class.\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;124;03m        The model to register.\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model_class, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig_class\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(model_class\u001b[38;5;241m.\u001b[39mconfig_class) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mstr\u001b[39m(config_class):\n\u001b[1;32m--> 584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model class you are passing has a `config_class` attribute that is not consistent with the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig class you passed (model has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_class\u001b[38;5;241m.\u001b[39mconfig_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and you passed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Fix \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone of those so they match!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    588\u001b[0m     )\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mregister(config_class, model_class, exist_ok\u001b[38;5;241m=\u001b[39mexist_ok)\n",
      "\u001b[1;31mValueError\u001b[0m: The model class you are passing has a `config_class` attribute that is not consistent with the config class you passed (model has <class 'transformers_modules.baichuan-inc.Baichuan-13B-Chat.e3e1498bb6b7fb0bcb5a65679c09b862d7c29301.configuration_baichuan.BaichuanConfig'> and you passed <class 'transformers_modules.Go4miii.DISC-FinLLM.8e235cb9e81f952702b0b90c5f3292a1089b0dba.configuration_baichuan.BaichuanConfig'>. Fix one of those so they match!"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation.utils import GenerationConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "model_path = \"Go4miii/DISC-FinLLM\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, torch_dtype=torch.float16, device_map=\"auto\", trust_remote_code=True\n",
    ")\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path, use_fast=False, trust_remote_code=True,\n",
    ")\n",
    "lora_path='Go4miii/DISC-FinLLM/Baichuan-13B-Chat-lora-Consulting'\n",
    "\n",
    "model = PeftModel.from_pretrained(model, lora_path\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"请解释一下什么是银行不良资产？\"},\n",
    "]\n",
    "response = model.chat(tokenizer, messages)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
